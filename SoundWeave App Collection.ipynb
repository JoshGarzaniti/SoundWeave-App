{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (0.59.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (0.13.0)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Requirement already satisfied: numpy in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: torch in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: yt-dlp in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (2025.1.15)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (2.159.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.37.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.24.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.8.30)\n",
      "Requirement already satisfied: isodate in c:\\users\\lotrc\\anaconda3\\lib\\site-packages (0.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tempfile (from versions: none)\n",
      "ERROR: No matching distribution found for tempfile\n"
     ]
    }
   ],
   "source": [
    "#Install needed libraries\n",
    "!pip install librosa\n",
    "!pip install numpy\n",
    "!pip install scipy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install torch\n",
    "!pip install yt-dlp\n",
    "!pip install google-api-python-client\n",
    "!pip install isodate\n",
    "!pip install tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yt_dlp\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial.distance import cosine\n",
    "from googleapiclient.discovery import build\n",
    "import time\n",
    "import random \n",
    "from googleapiclient.errors import HttpError\n",
    "import isodate \n",
    "from tempfile import NamedTemporaryFile #for Streamlit app\n",
    "import streamlit as st #streamlit app\n",
    "import joblib #streamlit/parallel jobs if needed\n",
    "import os #for saving my key in an env var\n",
    "from dotenv import load_dotenv #to load that env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get credentials for youtube data API\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"YOUTUBE_API_KEY\")  \n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\" #This should be a set feature (stay at youtube and just make sure I don't need to create a service account)\n",
    "YOUTUBE_API_VERSION = \"v3\" #Check under google's api service feature and make sure I check the box to enable the api latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of composers I want to parse through on youtube\n",
    "composers = [\n",
    "    \"Hans Zimmer\", \"John Williams\", \"James Newton Howard\", \n",
    "    \"Howard Shore\", \"Danny Elfman\", \"Ennio Morricone\", \n",
    "    \"Alexandre Desplat\", \"Thomas Newman\", \"Michael Giacchino\",\n",
    "    \"John Powell\", \"Harry Gregson-Williams\", \"Rupert Gregson-Williams\",\n",
    "    \"James Horner\", \"Lorne Balfe\", \"Kevin Kiner\", \"Henry Jackman\",\n",
    "    \"Dominic Lewis\", \"Patrick Doyle\", \"Nicholas Hooper\",\n",
    "    \"Joe Kraemer\", \"David Arnold\", \"John Barry\", \"Eric Serra\",\n",
    "    \"John Debney\", \"Brian Tyler\", \"Alan Silvestri\",\n",
    "    \"Mark Mothersbaugh\", \"Christophe Beck\", \"Joel P West\",\n",
    "    \"Ludwig Goransson\", \"Randy Newman\", \"Daniel Pemberton\",\n",
    "    \"Jerry Goldsmith\", \"Randy Edelman\", \"John Ottman\",\n",
    "    \"Mark Isham\", \"Alan Menken\", \"Klaus Badelt\",\n",
    "    \"Michael Kamen\", \"Marc Shaiman\", \"Adolph Deutsch\",\n",
    "    \"Trevor Rabin\", \"Gavin Greenaway\", \"Justin Hurwitz\",\n",
    "    \"Trent Reznor and Atticus Ross\", \"Trevor Jones\",\n",
    "    \"Elmer Bernstein\", \"Carlos Rafael Rivera\", \"Don Davis\",\n",
    "    \"Joe Hisaishi\", \"Tan Dun\", \"Dave Grusin\",\n",
    "    \"Dario Marianelli\", \"Steve Jablonsky\", \"Bill Conti\",\n",
    "    \"Ramin Djawadi\", \"Anthony Gonzalez\", \"Mychael Danna\",\n",
    "    \"Johnny Klimek\", \"Tom Tykwer\", \"Michael Paraskevas\",\n",
    "    \"Harold Faltermeyer\", \"Natalie Holt\", \"James Shearman\",\n",
    "    \"Robin Carolan\", \"Tyler Bates\", \"Bear McCreary\",\n",
    "    \"Nicholas Britell\", \"Carter Burwell\", \"Martin Phipps\",\n",
    "    \"Naoki Sato\", \"Takeshi Furukawa\", \"John Paesano\",\n",
    "    \"Benjamin Wallfisch\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Now working in: G:\\My Drive\\Personal Projects\n"
     ]
    }
   ],
   "source": [
    "personal_projects_path = r\"G:\\My Drive\\Personal Projects\" #update my path to my personal project folder\n",
    "if personal_projects_path not in sys.path:\n",
    "    sys.path.append(personal_projects_path)\n",
    "\n",
    "os.chdir(personal_projects_path) \n",
    "print(f\"✅ Now working in: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Skipping Hans Zimmer, already has 5 videos.\n",
      "⏭️ Skipping John Williams, already has 5 videos.\n",
      "⏭️ Skipping James Newton Howard, already has 5 videos.\n",
      "⏭️ Skipping Howard Shore, already has 5 videos.\n",
      "⏭️ Skipping Danny Elfman, already has 5 videos.\n",
      "⏭️ Skipping Ennio Morricone, already has 5 videos.\n",
      "⏭️ Skipping Alexandre Desplat, already has 5 videos.\n",
      "🎼 Fetching 5 tracks for Thomas Newman...\n",
      "✅ Added: https://www.youtube.com/watch?v=gqo46lt-8Q4 (3.0 min)\n",
      "✅ Added: https://www.youtube.com/watch?v=kZbf9T_PCgs (3.0 min)\n",
      "✅ Added: https://www.youtube.com/watch?v=cc-O24c-q9M (3.0 min)\n",
      "✅ Added: https://www.youtube.com/watch?v=CPPEw17VmcY (5.0 min)\n"
     ]
    }
   ],
   "source": [
    "#Info on requests:\n",
    "#The search request counts as one API call per page of results.\n",
    "#The video details request is made for each video returned in the search results.\n",
    "#Since each page fetches up to 25 videos, that means each full page of results adds ~26 requests (1 search request + 25 video details requests).\n",
    "\n",
    "\n",
    "#Request Tracker\n",
    "MAX_DAILY_REQUESTS = 10000\n",
    "requests_made = 0\n",
    "\n",
    "#Create a file to store video urls\n",
    "URL_FILE = r\"video_urls.txt\"\n",
    "full_path = os.path.abspath(URL_FILE)\n",
    "\n",
    "#Set a max number of files for each artist (we will update this after each full iter so once everyone has 5 we will move to 10 etc\n",
    "MAX_VIDEOS = 5\n",
    "\n",
    "#Read the existing files for each artist\n",
    "video_counts = {composer: 0 for composer in composers}\n",
    "existing_videos = {}\n",
    "#Count the number of unique files for each artist\n",
    "if os.path.exists(URL_FILE):\n",
    "    with open(URL_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            composer, url = line.strip().split(\" | \")\n",
    "            existing_videos.setdefault(composer, []).append(url)\n",
    "            video_counts[composer] += 1\n",
    "\n",
    "#Create a function to fetch videos\n",
    "def fetch_composer_ost_links(composer, max_videos=5):\n",
    "    global requests_made\n",
    "\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
    "    query = f\"{composer} ost\"\n",
    "    links = []\n",
    "    next_page_token = None\n",
    "#Define keywords we need to not have pulled in our videos...filter out all of these\n",
    "    exclude_keywords = [\n",
    "        \"live\", \"interview\", \"trailer\", \"behind the scenes\", \"making of\",\n",
    "        \"creating\", \"composing\", \"inspiration\", \"mix\", \"remix\", \"medley\",\n",
    "        \"suite\", \"score analysis\", \"cover of\", \"analysis\", \"analyzing\",\n",
    "        \"producing\", \"orchestrating\", \"orchestration\", \"recording\", \"concert\",\n",
    "        \"Top 5\", \"top 5\", \"Top 10\", \"top 10\", \"Best of\", \"best of\", \"Boston Pops\", \"boston pops\",\n",
    "        \"Greatest Hits\", \"greatest hits\", \"Best Pieces\", \"best pieces\", \"Best Works\", \"best works\"\n",
    "    ]\n",
    "#while we are unde the api daily limits\n",
    "    while len(links) < max_videos and requests_made + 1 <= MAX_DAILY_REQUESTS:\n",
    "        if requests_made >= MAX_DAILY_REQUESTS:\n",
    "            print(\"🚨 API limit reached, stopping collection.\")\n",
    "            break\n",
    "\n",
    "        # Search request (counts as 1 request)\n",
    "        search_response = youtube.search().list(\n",
    "            q=query,\n",
    "            part=\"id,snippet\",\n",
    "            type=\"video\",\n",
    "            maxResults=min(25, max_videos - len(links)),\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "        requests_made += 1  # Track search request\n",
    "\n",
    "        time.sleep(random.uniform(1, 3))  # Sleep timer between requests\n",
    "\n",
    "        video_ids = []\n",
    "        for item in search_response.get(\"items\", []):\n",
    "            title = item[\"snippet\"][\"title\"].lower()\n",
    "            video_id = item[\"id\"][\"videoId\"]\n",
    "            video_url = f\"https://www.youtube.com/watch?v={video_id}\" #Tell me the name of the url\n",
    "\n",
    "            if video_url in existing_videos.get(composer, []) or video_url in links:\n",
    "                continue  #No duplicate tracks\n",
    "            \n",
    "            if not any(keyword in title for keyword in exclude_keywords):\n",
    "                if any(term in title for term in [\"ost\", \"original motion picture\", \"soundtrack\", \"original score\", \"score\"]):\n",
    "                    video_ids.append(video_id)  #Collect video IDs for batch request\n",
    "\n",
    "        if not video_ids:\n",
    "            next_page_token = search_response.get(\"nextPageToken\")\n",
    "            if not next_page_token:\n",
    "                break  #Stop if no more pages\n",
    "            continue\n",
    "\n",
    "        #Video details request (counts as len(video_ids) requests)\n",
    "        try:\n",
    "            video_response = youtube.videos().list(\n",
    "                part=\"contentDetails\",\n",
    "                id=\",\".join(video_ids)  #Batch request for efficiency (looking into this)\n",
    "            ).execute()\n",
    "            requests_made += len(video_ids)  \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error fetching video details: {e}\") #if there's an error with video details skip the song\n",
    "            continue\n",
    "\n",
    "        for item in video_response.get(\"items\", []):\n",
    "            video_id = item[\"id\"]\n",
    "            video_url = f\"https://www.youtube.com/watch?v={video_id}\" #the actual data we're pulling\n",
    "            content_details = item.get(\"contentDetails\", {})\n",
    "\n",
    "            if \"duration\" not in content_details:\n",
    "                print(f\"⚠️ Skipping {video_url} (Missing duration info)\") #if there's no video duration info, skip the song\n",
    "                continue\n",
    "\n",
    "            duration = content_details[\"duration\"]\n",
    "            duration_seconds = isodate.parse_duration(duration).total_seconds()\n",
    "\n",
    "            if 60 <= duration_seconds <= 12 * 60:  #12 minute maximum video length\n",
    "                links.append(video_url)\n",
    "                print(f\"✅ Added: {video_url} ({duration_seconds // 60} min)\")\n",
    "\n",
    "        next_page_token = search_response.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break  #if you run out of pages stop\n",
    "\n",
    "        time.sleep(random.uniform(5, 15))  #sleep delay\n",
    "\n",
    "    return links\n",
    "\n",
    "\n",
    "#find videos for composers that haven't reached max\n",
    "for composer in composers:\n",
    "    if video_counts[composer] >= MAX_VIDEOS:\n",
    "        print(f\"⏭️ Skipping {composer}, already has {MAX_VIDEOS} videos.\")\n",
    "        continue  #kkip composers with max \n",
    "\n",
    "    try:\n",
    "        print(f\"🎼 Fetching {MAX_VIDEOS - video_counts[composer]} tracks for {composer}...\") #tell me when you move onto a new artist\n",
    "        composer_links = fetch_composer_ost_links(composer, max_videos=MAX_VIDEOS - video_counts[composer])\n",
    "\n",
    "        new_urls = [f\"{composer} | {url}\" for url in composer_links]\n",
    "        video_counts[composer] += len(new_urls)\n",
    "\n",
    "        # Append new URLs to the file\n",
    "        with open(URL_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            for url in new_urls:\n",
    "                f.write(url + \"\\n\")\n",
    "\n",
    "        print(f\"✅ Added {len(new_urls)} tracks for {composer}\") #tell me you're adding tracks for each artist\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error with {composer}: {e}\") #if there's an error with certain artists let's pull them\n",
    "#Tell me where we are saving data at the end\n",
    "print(f\"📂 URLs saved to: {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
