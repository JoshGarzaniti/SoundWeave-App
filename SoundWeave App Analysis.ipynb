{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c9a5a-00cb-4808-9bc7-b0ec8f7c6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yt_dlp\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial.distance import cosine\n",
    "from googleapiclient.discovery import build\n",
    "import time\n",
    "import random \n",
    "from googleapiclient.errors import HttpError\n",
    "import isodate \n",
    "from tempfile import NamedTemporaryFile #for Streamlit app\n",
    "import streamlit as st #streamlit app\n",
    "import joblib #streamlit/parallel jobs if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d77f7-7143-4ba0-bf28-1e7acd7a2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for the archive file to keep track of downloaded videos\n",
    "archive_file = 'downloaded_videos.txt'\n",
    "\n",
    "#Download options\n",
    "download_options = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'wav',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl': 'film_scores/%(title)s.%(ext)s',\n",
    "    'ffmpeg_location': 'C:\\\\ffmpeg\\\\bin',  \n",
    "    'download_archive': archive_file,  #We need to prevent re-downloading (it was looping before)\n",
    "    'noplaylist': False,  # Set to False since  some of the data we are downloading comes from playlists\n",
    "}\n",
    "\n",
    "#Ensure the output directory exists\n",
    "os.makedirs(\"film_scores\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00c022-395f-4e2d-9101-e35ef8ad9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Features\n",
    "audio_folder = \"film_scores/\" #This folder is in my google drive under unstructed data analytics \n",
    "\n",
    "dataset = [] #create an empy data set \n",
    "\n",
    "print(\"Starting feature extraction...\")\n",
    "\n",
    "for file in os.listdir(audio_folder): #create a for loop for .wav files in that directory and load all of the txt.files in \n",
    "    if file.endswith(\".wav\"):\n",
    "        print(f\"Processing {file}...\")  # Print current file being processed so we can track for debugging\n",
    "        file_path = os.path.join(audio_folder, file)\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    " #Pull out mfccs(frequencies), rms energy(loudness over time...basically in decibals, mfccs, so the frequency of sound waves, and zero crossing rate (times it crosses over the x axis)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).mean(axis=1) #doing more research on these\n",
    "        rms_energy = librosa.feature.rms(y=y).mean()\n",
    "        zcr = librosa.feature.zero_crossing_rate(y).mean()\n",
    "\n",
    "        dataset.append([file, *mfccs, rms_energy, zcr]) #pull all 3 variables and put them together into a dataframe\n",
    "\n",
    "#Save to CSV\n",
    "columns = [\"File_name\"] + [f\"mfcc_{i}\" for i in range(13)] + [\"rms_energy\", \"zcr\"]\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=columns)\n",
    "\n",
    "df.to_csv(\"Film_Scores_Dataset.csv\", index=False) #Create a csv (Might update this to an absolute path later in ym c drive)\n",
    "\n",
    "print(\"Dataset saved as Film_Scores_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa76a7-8bbe-4b4a-a6b3-efb2bae7372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Files in the audio folder:\")\n",
    "for file in os.listdir(audio_folder): #List out all of the tracks I have \n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7bbc1c-32d5-4cdf-a075-02f29929676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot waveforms (you may need to specify an actual file path if needed)\n",
    "file_name = \"Star Wars Episode IV A New Hope (1977) Soundtrack 23 The Battle of Yavin.wav\" #Here is where we will select the one track we want to transition FROM\n",
    "file_path = os.path.join(audio_folder, file_name.strip()) \n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"Loading and Processing File\") #Tell us if this file exists and if it doads, load it in\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    #Spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max) #this helps us visualize frequencies by decibal level/instrument range\n",
    "    \n",
    "    #MFCCs for more frequency visual analysis\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13) \n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    \n",
    "    #Zero-Crossing Rate (ZCR) to visualize where it crosses over x axis\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
    "    \n",
    "    #RMS Energy to visualize loudness\n",
    "    rms_energy = librosa.feature.rms(y=y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf4c33-16d3-4914-8679-6a7d1727e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Plotting the  Spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(D, x_axis='time', y_axis='log', sr=sr)\n",
    "plt.title('Spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d2b49-7343-4f0a-90cb-bfd2410af361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting MFCCs\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(mfccs, x_axis='time', sr=sr)\n",
    "plt.title('MFCCs')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e4da4-fcc4-4650-8979-44d613d5e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Zero-Crossing Rate\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(zcr, label=\"Zero Crossing Rate\")\n",
    "plt.title('Zero Crossing Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45ab7f-8ebd-4b6a-95d3-deb4d841a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting RMS Energy\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(rms_energy, label=\"RMS Energy\")\n",
    "plt.title('RMS Energy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a73591-6cd3-4c3d-becf-097d8f1cb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Peaks in RMS Energy (This can help us detect relative climaxes in the song that can be compared to other tracks)\n",
    "peaks, _ = find_peaks(rms_energy, height=np.mean(rms_energy))\n",
    "peak_times = librosa.frames_to_time(peaks, sr=sr)\n",
    "print(\"Recommended Transition Times:\", peak_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8fbef2-dab7-4ac9-8500-96895055f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a Model\n",
    "#Variable index\n",
    "#Ensuring that rms_energy.mean() and zcr.mean() are the same shape as mfccs_mean\n",
    "rms_energy_mean = rms_energy.mean()  \n",
    "zcr_mean = zcr.mean()  \n",
    "\n",
    "#Repeat scalar values to match the length of mfccs_mean\n",
    "rms_energy_mean = np.repeat(rms_energy_mean, len(mfccs_mean))\n",
    "zcr_mean = np.repeat(zcr_mean, len(mfccs_mean))\n",
    "\n",
    "#Stacking them together\n",
    "features = np.column_stack([mfccs_mean, rms_energy_mean, zcr_mean])\n",
    "print(\"Feature Matrix (first 5 rows):\", features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ca8ec-d88d-4766-ba15-068576789091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "print(\"Splitting data for training...\")\n",
    "X = features  # Feature matrix (MFCCs + RMS Energy + ZCR)\n",
    "Y = np.random.randint(0, 2, X.shape[0]) \n",
    "\n",
    "#Actual splits at 80% train 20% test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Training the model (This is a classification model i.e ranked ordered levels based on similarity)...checking to see what the target variable is \n",
    "print(\"Training RandomForestClassifier...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#Predict with the model and check accuracy\n",
    "Y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "#Recommend transitions\n",
    "print(\"Recommending transition times...\")\n",
    "rms_energy = librosa.feature.rms(y=y)[0]\n",
    "peaks, _ = find_peaks(rms_energy, height=np.mean(rms_energy))\n",
    "peak_times = librosa.frames_to_time(peaks, sr=sr)\n",
    "print(\"Recommended Transition Times:\", peak_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20b1ce-1266-4ada-a0f7-49ed535c5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current working directory:\", os.getcwd()) #Tell me where I'm working out of just to make sure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ce184-68b4-4e14-966c-8d6d50ea9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a function to extract features \n",
    "def extract_features_with_labels(file_path, window_size=2048, hop_size=512):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    #Extract features from each file in our file path\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    rms = librosa.feature.rms(y=y)[0]\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=y)[0]\n",
    "\n",
    "    #Convert frames to time values\n",
    "    times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_size)\n",
    "\n",
    "    #Detect peaks in RMS (possible transitions)\n",
    "    peaks, _ = find_peaks(rms, height=np.mean(rms) * 1.2)  # Peak = 1.2x mean energy (Might calibrate need to research)\n",
    "\n",
    "    #Label each frame (1 = transition, 0 = not)\n",
    "    labels = np.zeros_like(rms)\n",
    "    labels[peaks] = 1  # Mark peaks as transitions\n",
    "\n",
    "    #Create a list to store the data from each feature\n",
    "    data = []\n",
    "    for i in range(len(rms)):\n",
    "        features = list(mfccs[:, i]) + [rms[i], zcr[i], labels[i]]\n",
    "        data.append(features)\n",
    "\n",
    "    return pd.DataFrame(data, columns=[f\"MFCC_{i}\" for i in range(13)] + [\"RMS\", \"ZCR\", \"Label\"])\n",
    "\n",
    "#This is where we will store them\n",
    "audio_folder = r\"G:\\My Drive\\Unstructured Data Analytics\\film_scores\"\n",
    "dataframes = []\n",
    "\n",
    "# Process each file\n",
    "for file_name in os.listdir(audio_folder):\n",
    "    if file_name.endswith('.wav'):\n",
    "        file_path = os.path.join(audio_folder, file_name)\n",
    "        try:\n",
    "            df = extract_features_with_labels(file_path)\n",
    "            df[\"File\"] = file_name  # Add file name for tracking\n",
    "            dataframes.append(df)\n",
    "            print(f\"Processed: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "#Create a final dataframe\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "#Save for model training\n",
    "final_df.to_csv(\"transition_training_data.csv\", index=False)\n",
    "print(\"Data saved to transition_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e505f7-2121-4542-af0e-0d88960db964",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training Random Forest Binary Classification Model\n",
    "\n",
    "df = pd.read_csv(\"transition_training_data.csv\")\n",
    "\n",
    "#Split into X and Y\n",
    "X = df.drop(columns=[\"Label\", \"File\"])  # Features (MFCCs, RMS, ZCR)\n",
    "Y = df[\"Label\"]  # Labels (1 = transition, 0 = no transition)\n",
    "\n",
    "#Create an 80/20 train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "#The model itself\n",
    "print(\"Training RandomForestClassifier...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#Predict with the Classification model\n",
    "Y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "#Save it for future\n",
    "import joblib\n",
    "joblib.dump(model, \"transition_model.pkl\")\n",
    "print(\"Model saved as transition_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed7014-a882-4df4-9cbd-c68a6a5f3f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new prediction on untrained data with the model\n",
    "model = joblib.load(\"transition_model.pkl\")\n",
    "\n",
    "#Load the new song's features\n",
    "new_song = extract_features_with_labels(\"new_song.wav\") #Insert song here \n",
    "\n",
    "#Predict transitions\n",
    "X_new = new_song.drop(columns=[\"Label\"])  # No labels needed for prediction\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "#Get transition times\n",
    "transition_times = new_song[\"Time\"][predictions == 1]\n",
    "\n",
    "print(\"Predicted transition times:\", transition_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771ef44-810a-40c0-b302-55e8d13105c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(\"transition_model.pkl\")\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features_with_labels(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).mean(axis=1)\n",
    "    rms = librosa.feature.rms(y=y).mean()\n",
    "    zcr = librosa.feature.zero_crossing_rate(y).mean()\n",
    "    features = np.hstack([mfccs, rms, zcr]).reshape(1, -1)  # Ensure correct shape\n",
    "    return features\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Music Transition Prediction App\")\n",
    "st.write(\"Upload a .wav file to predict the best transition points.\")\n",
    "\n",
    "# File uploader\n",
    "uploaded_file = st.file_uploader(\"Upload a .wav file\", type=[\"wav\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    # Save uploaded file to a temporary location\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as temp_file:\n",
    "        temp_file.write(uploaded_file.read())\n",
    "        temp_file_path = temp_file.name\n",
    "\n",
    "    # Extract features\n",
    "    new_song_features = extract_features_with_labels(temp_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
